{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.initializers import HeNormal as w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/data'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_rows=128\n",
    "img_cols=128\n",
    "num_channel=1\n",
    "num_epoch=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um_classes = 4\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\tprint ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UNet3D(chainer.Chain):\n",
    "    def __init__(self, in_channel, n_classes):\n",
    "        self.in_channel = in_channel\n",
    "        super(UNet3D, self).__init__(\n",
    "            c0=L.ConvolutionND(3, self.in_channel, 32, 3, 1, 1, initial_bias=None),\n",
    "            c1=L.ConvolutionND(3, 32, 64, 3, 1, 1, initial_bias=None),\n",
    "\n",
    "            c2=L.ConvolutionND(3, 64, 64, 3, 1, 1, initial_bias=None),\n",
    "            c3=L.ConvolutionND(3, 64, 128, 3, 1, 1, initial_bias=None),\n",
    "\n",
    "            c4=L.ConvolutionND(3, 128, 128, 3, 1, 1, initial_bias=None),\n",
    "            c5=L.ConvolutionND(3, 128, 256, 3, 1, 1, initial_bias=None),\n",
    "\n",
    "            c6=L.ConvolutionND(3, 256, 256, 3, 1, 1, initial_bias=None),\n",
    "            c7=L.ConvolutionND(3, 256, 512, 3, 1, 1, initial_bias=None),\n",
    "\n",
    "            dc9=L.DeconvolutionND(3, 512, 512, 2, 2, initial_bias=None),\n",
    "            dc8=L.ConvolutionND(3, 256 + 512, 256, 3, 1, 1, initial_bias=None),\n",
    "            dc7=L.ConvolutionND(3, 256, 256, 3, 1, 1, initial_bias=None),\n",
    "\n",
    "            dc6=L.DeconvolutionND(3, 256, 256, 2, 2, initial_bias=None),\n",
    "            dc5=L.ConvolutionND(3, 128 + 256, 128, 3, 1, 1, initial_bias=None),\n",
    "            dc4=L.ConvolutionND(3, 128, 128, 3, 1, 1, initial_bias=None),\n",
    "\n",
    "            dc3=L.DeconvolutionND(3, 128, 128, 2, 2, initial_bias=None),\n",
    "            dc2=L.ConvolutionND(3, 64 + 128, 64, 3, 1, 1, initial_bias=None),\n",
    "            dc1=L.ConvolutionND(3, 64, 64, 3, 1, 1, initial_bias=None),\n",
    "\n",
    "            dc0=L.ConvolutionND(3, 64, n_classes, 1, 1, initial_bias=None),\n",
    "\n",
    "        )\n",
    "        self.train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __call__(self, x, use_cudnn=False):\n",
    "        test = not self.train\n",
    "        e0 = F.relu(self.c0(x), use_cudnn)\n",
    "        syn0 = F.relu(self.c1(e0), use_cudnn)    \n",
    "        del e0\n",
    "\n",
    "        e1 = F.max_pooling_nd(syn0, 2, 2)\n",
    "        e2 = F.relu(self.c2(e1), use_cudnn)\n",
    "        syn1 = F.relu(self.c3(e2), use_cudnn)\n",
    "        del e1, e2\n",
    "\n",
    "        e3 = F.max_pooling_nd(syn1, 2, 2)\n",
    "        e4 = F.relu(self.c4(e3), use_cudnn)\n",
    "        syn2 = F.relu(self.c5(e4), use_cudnn)\n",
    "        del e3, e4\n",
    "        \n",
    "        e5 = F.max_pooling_nd(syn2, 2, 2)\n",
    "        e6 = F.relu(self.c6(e5), use_cudnn)\n",
    "        e7 = F.relu(self.c7(e6), use_cudnn)\n",
    "        del e5, e6\n",
    "\n",
    "        d9 = F.concat([self.dc9(e7), syn2])\n",
    "        del e7, syn2\n",
    "\n",
    "        d8 = F.relu(self.dc8(d9), use_cudnn)\n",
    "        d7 = F.relu(self.dc7(d8), use_cudnn)\n",
    "        del d9, d8\n",
    "\n",
    "        d6 = F.concat([self.dc6(d7), syn1])\n",
    "        del d7, syn1\n",
    "\n",
    "        d5 = F.relu(self.dc5(d6), use_cudnn)\n",
    "        d4 = F.relu(self.dc4(d5), use_cudnn)\n",
    "        del d6, d5\n",
    "\n",
    "        d3 = F.concat([self.dc3(d4), syn0])\n",
    "        del d4, syn0\n",
    "\n",
    "        d2 = F.relu(self.dc2(d3), use_cudnn)\n",
    "        d1 = F.relu(self.dc1(d2), use_cudnn)\n",
    "        del d3, d2\n",
    "\n",
    "        d0 = self.dc0(d1)\n",
    "        return d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
